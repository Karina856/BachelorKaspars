{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc1071e6",
   "metadata": {
    "id": "bc1071e6"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ndozuIytf6MW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24909,
     "status": "ok",
     "timestamp": 1680844829020,
     "user": {
      "displayName": "Kaspars Pakulis",
      "userId": "15620035111695870681"
     },
     "user_tz": -180
    },
    "id": "ndozuIytf6MW",
    "outputId": "0f6f08b5-2c38-4c3d-a0e0-ab2b781bc3d4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edd4cd26",
   "metadata": {
    "executionInfo": {
     "elapsed": 6493,
     "status": "ok",
     "timestamp": 1680844794927,
     "user": {
      "displayName": "Kaspars Pakulis",
      "userId": "15620035111695870681"
     },
     "user_tz": -180
    },
    "id": "edd4cd26"
   },
   "outputs": [],
   "source": [
    "#Import everything\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from math import log2\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import torchvision\n",
    "from scipy.stats import truncnorm\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import save_image\n",
    "import torch.optim as optim\n",
    "from torch.nn import Module, Sequential, Conv2d, ConvTranspose2d, LeakyReLU, BatchNorm2d, ReLU, Tanh, Sigmoid, BCELoss \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.backends.cudnn.benchmarks = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9adb904",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1680844829020,
     "user": {
      "displayName": "Kaspars Pakulis",
      "userId": "15620035111695870681"
     },
     "user_tz": -180
    },
    "id": "e9adb904"
   },
   "outputs": [],
   "source": [
    "# Always good to check if gpu support available or not\n",
    "dev = 'cuda:0' if torch.cuda.is_available() == True else 'cpu'\n",
    "device = torch.device(dev)\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb681a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_center(pil_img, crop_width, crop_height):\n",
    "    img_width, img_height = pil_img.size\n",
    "    return pil_img.crop(((img_width - crop_width) // 2,\n",
    "                         (img_height - crop_height) // 2,\n",
    "                         (img_width + crop_width) // 2,\n",
    "                         (img_height + crop_height) // 2))\n",
    "def crop_max_square(pil_img):\n",
    "    return crop_center(pil_img, min(pil_img.size), min(pil_img.size))\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "f = r'C:/Users/Unreal User/Downloads/Nevus Database/train'\n",
    "j=1\n",
    "for file in os.listdir(f):\n",
    "    f_img = f+\"/\"+file\n",
    "    images = Image.open(f_img)\n",
    "    img_r = crop_max_square(images)\n",
    "    img_c = img_r.resize((1024,1024))\n",
    "    img_c.save(f_img)\n",
    "    j+=1\n",
    "\n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59c6a88d",
   "metadata": {
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1680844916812,
     "user": {
      "displayName": "Kaspars Pakulis",
      "userId": "15620035111695870681"
     },
     "user_tz": -180
    },
    "id": "59c6a88d"
   },
   "outputs": [],
   "source": [
    "START_TRAIN_AT_IMG_SIZE = 256\n",
    "DATASET = 'C:/Users/Unreal User/Downloads/Nevus Database'\n",
    "CHECKPOINT_G = \"netG-150-M.pth\"\n",
    "CHECKPOINT_D = \"netD-150-M.pth\"\n",
    "SAVE_MODEL = True\n",
    "LOAD_MODEL = True\n",
    "LEARNING_RATE = 1e-3\n",
    "BATCH_SIZES = [32, 32, 32, 16, 16, 16, 8, 4]\n",
    "CHANNELS_IMG = 3\n",
    "Z_DIM = 256  # should be 512 in original paper\n",
    "IN_CHANNELS = 256 # should be 512 in original paper\n",
    "D_ITERATIONS = 1\n",
    "LAMBDA_GP = 10\n",
    "PROGRESSIVE_EPOCHS = [100] * len(BATCH_SIZES)\n",
    "FIXED_NOISE = torch.randn(7, Z_DIM, 1, 1).to(device)\n",
    "NUM_WORKERS = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbf1f6a6",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1680844829021,
     "user": {
      "displayName": "Kaspars Pakulis",
      "userId": "15620035111695870681"
     },
     "user_tz": -180
    },
    "id": "cbf1f6a6"
   },
   "outputs": [],
   "source": [
    "def gradient_penalty(critic, real, fake, alpha, train_step, device=\"cpu\"):\n",
    "    BATCH_SIZE, C, H, W = real.shape\n",
    "    beta = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)\n",
    "    interpolated_images = real * beta + fake.detach() * (1 - beta)\n",
    "    interpolated_images.requires_grad_(True)\n",
    "\n",
    "    # Calculate critic scores\n",
    "    mixed_scores = critic(interpolated_images, alpha, train_step)\n",
    "\n",
    "    # Take the gradient of the scores with respect to the images\n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=interpolated_images,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=torch.ones_like(mixed_scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    gradient = gradient.view(gradient.shape[0], -1)\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n",
    "    return gradient_penalty\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    checkpoint = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    checkpoint = torch.load(checkpoint_file)\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "\n",
    "    # If we don't do this then it will just have learning rate of old checkpoint\n",
    "    # and it will lead to many hours of debugging \\:\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr\n",
    "\n",
    "def seed_everything(seed=69):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5681e3d8",
   "metadata": {
    "id": "5681e3d8"
   },
   "source": [
    "#Prepare the data\n",
    "# path to the image directory\n",
    "dir_data  = r'C:\\Users\\Unreal User\\Downloads\\Melanoma_Resize\\Melanoma Resize'\n",
    " \n",
    "# setting image shape to 1024x1024\n",
    "img_shape = (1024, 1024, 3)\n",
    " \n",
    "# listing out all file names\n",
    "nm_imgs   = np.sort(os.listdir(dir_data)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579c905b",
   "metadata": {
    "id": "579c905b"
   },
   "source": [
    "X_train = []\n",
    "for file in nm_imgs:\n",
    "    try:\n",
    "        img = Image.open(dir_data+'/'+file)\n",
    "        img = img.convert('RGB')\n",
    "        img = img.resize((1024,1024))\n",
    "        img = np.asarray(img)/255\n",
    "        X_train.append(img)\n",
    "    except:\n",
    "        print(\"something went wrong\")\n",
    " \n",
    "X_train = np.array(X_train)\n",
    "X_train.shape\n",
    "savez_compressed('kaggle_images_1024x1024.npz', X_train) #Save to a numpy array for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7509ad26",
   "metadata": {
    "id": "7509ad26"
   },
   "source": [
    "#Numpy helper function for displaying\n",
    "# plot images in a nxn grid\n",
    " \n",
    "def plot_images(imgs, grid_size = 5):\n",
    "    \"\"\"\n",
    "    imgs: vector containing all the numpy images\n",
    "    grid_size: 2x2 or 5x5 grid containing images\n",
    "    \"\"\"\n",
    "     \n",
    "    fig = plt.figure(figsize = (8, 8))\n",
    "    columns = rows = grid_size\n",
    "    plt.title(\"Training Images\")\n",
    " \n",
    "    for i in range(1, columns*rows +1):\n",
    "        plt.axis(\"off\")\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(imgs[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d558bec5",
   "metadata": {
    "id": "d558bec5"
   },
   "source": [
    "#Dataset class cause Pytorch likes them:\n",
    "class HumanFacesDataset(Dataset):\n",
    "    \"\"\"Human Faces dataset.\"\"\"\n",
    " \n",
    "    def __init__(self, npz_imgs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            npz_imgs (string): npz file with all the images (created in gan.ipynb)\n",
    "        \"\"\"\n",
    "        self.imgs = npz_imgs\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    " \n",
    "        image = self.imgs[idx]\n",
    " \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "614c734a",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1680844829021,
     "user": {
      "displayName": "Kaspars Pakulis",
      "userId": "15620035111695870681"
     },
     "user_tz": -180
    },
    "id": "614c734a"
   },
   "outputs": [],
   "source": [
    "def get_loader(image_size):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.Normalize(\n",
    "                [0.5 for _ in range(CHANNELS_IMG)],\n",
    "                [0.5 for _ in range(CHANNELS_IMG)],\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    batch_size = BATCH_SIZES[int(log2(image_size / 4))]\n",
    "    dataset = datasets.ImageFolder(root=DATASET, transform=transform)\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "    return loader, dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41adb6b3",
   "metadata": {
    "id": "41adb6b3"
   },
   "source": [
    "kernel size given by 1st tut = 4\n",
    "                  by 2nd tut = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "018269a1",
   "metadata": {
    "executionInfo": {
     "elapsed": 937,
     "status": "ok",
     "timestamp": 1680844829955,
     "user": {
      "displayName": "Kaspars Pakulis",
      "userId": "15620035111695870681"
     },
     "user_tz": -180
    },
    "id": "018269a1"
   },
   "outputs": [],
   "source": [
    "factors = [1,1,1,1,1/2, 1/4, 1/8, 1/16] #For progressive learning\n",
    "#Define Layer clases\n",
    "class WSConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, gain=2):\n",
    "        super(WSConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.scale = (gain / (in_channels * (kernel_size ** 2))) ** 0.5\n",
    "        self.bias = self.conv.bias\n",
    "        self.conv.bias = None\n",
    "        \n",
    "        nn.init.normal_(self.conv.weight)\n",
    "        nn.init.zeros_(self.bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.conv(x * self.scale) + self.bias.view(1, self.bias.shape[0], 1, 1)\n",
    "\n",
    "class PixelNorm(nn.Module):#Can be excluted and simply use BatchNorm\n",
    "    def __init__(self):\n",
    "        super(PixelNorm, self).__init__()\n",
    "        self.epsilon = 1e-8\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x / torch.sqrt(torch.mean(x ** 2, dim=1, keepdim=True) + self.epsilon)\n",
    "    \n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_pixelnorm=True):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.use_pn = use_pixelnorm\n",
    "        self.conv1 = WSConv2d(in_channels, out_channels)\n",
    "        self.conv2 = WSConv2d(out_channels, out_channels)\n",
    "        self.leaky = nn.LeakyReLU(0.2)\n",
    "        self.pn = PixelNorm()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.leaky(self.conv1(x))\n",
    "        x = self.pn(x) if self.use_pn else x\n",
    "        x = self.leaky(self.conv2(x))\n",
    "        x = self.pn(x) if self.use_pn else x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NgnA-PhntfzC",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1680806796972,
     "user": {
      "displayName": "Kaspars Pakulis",
      "userId": "15620035111695870681"
     },
     "user_tz": -180
    },
    "id": "NgnA-PhntfzC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3debeb7",
   "metadata": {
    "id": "e3debeb7"
   },
   "source": [
    "Potentially replace in initial layer th ePixelNorm and ConvTranspose layers with a WSConv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47fa8967",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1680844832554,
     "user": {
      "displayName": "Kaspars Pakulis",
      "userId": "15620035111695870681"
     },
     "user_tz": -180
    },
    "id": "47fa8967"
   },
   "outputs": [],
   "source": [
    "#Defining the Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,z_dim, in_channels, img_channels=3):\n",
    "        super(Generator, self).__init__()\n",
    "        self.initial = nn.Sequential(\n",
    "            PixelNorm(),\n",
    "            nn.ConvTranspose2d(z_dim, in_channels, 4, 1, 0), #1x1 -> 4x4\n",
    "            nn.LeakyReLU(0.2),\n",
    "            WSConv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            PixelNorm(),\n",
    "        )\n",
    "\n",
    "        self.initial_rgb = WSConv2d(in_channels, img_channels, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        self.prog_blocks, self.rgb_layers = (nn.ModuleList([]), nn.ModuleList([self.initial_rgb]),)\n",
    "\n",
    "        for i in range(len(factors) - 1):  # -1 to prevent index error because of factors[i+1]\n",
    "            conv_in_c = int(in_channels * factors[i])\n",
    "            conv_out_c = int(in_channels * factors[i + 1])\n",
    "            self.prog_blocks.append(ConvBlock(conv_in_c, conv_out_c))\n",
    "            self.rgb_layers.append(WSConv2d(conv_out_c, img_channels, kernel_size=1, stride=1, padding=0))\n",
    "            \n",
    "    def fade_in(self, alpha, upscaled, generated):\n",
    "        # alpha should be scalar within [0, 1], and upscale.shape == generated.shape\n",
    "        return torch.tanh(alpha * generated + (1 - alpha) * upscaled)\n",
    "    \n",
    "    def forward(self, x, alpha, steps): #steps=0 (4x4), steps=1 (8x8)\n",
    "        out = self.initial(x) \n",
    "\n",
    "        if steps == 0:\n",
    "            return self.initial_rgb(out)\n",
    "\n",
    "        for step in range(steps):\n",
    "            upscaled = F.interpolate(out, scale_factor=2, mode=\"nearest\")\n",
    "            out = self.prog_blocks[step](upscaled)\n",
    "\n",
    "        # The number of channels in upscale will stay the same, while\n",
    "        # out which has moved through prog_blocks might change. To ensure\n",
    "        # we can convert both to rgb we use different rgb_layers\n",
    "        # (steps-1) and steps for upscaled, out respectively\n",
    "        final_upscaled = self.rgb_layers[steps - 1](upscaled)\n",
    "        final_out = self.rgb_layers[steps](out)\n",
    "        return self.fade_in(alpha, final_upscaled, final_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "287c5091",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1680844834755,
     "user": {
      "displayName": "Kaspars Pakulis",
      "userId": "15620035111695870681"
     },
     "user_tz": -180
    },
    "id": "287c5091"
   },
   "outputs": [],
   "source": [
    "# Defining the Discriminator class\n",
    " \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels, img_channels=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.prog_blocks, self.rgb_layers = nn.ModuleList([]), nn.ModuleList([])\n",
    "        self.leaky = nn.LeakyReLU(0.2)\n",
    "\n",
    "        # here we work back ways from factors because the discriminator\n",
    "        # should be mirrored from the generator. So the first prog_block and\n",
    "        # rgb layer we append will work for input size 1024x1024, then 512->256-> etc\n",
    "        for i in range(len(factors) - 1, 0, -1):\n",
    "            conv_in_c = int(in_channels * factors[i])\n",
    "            conv_out_c = int(in_channels * factors[i - 1])\n",
    "            self.prog_blocks.append(ConvBlock(conv_in_c, conv_out_c, use_pixelnorm=False))\n",
    "            self.rgb_layers.append(WSConv2d(img_channels, conv_in_c, kernel_size=1, stride=1, padding=0))\n",
    "        \n",
    "        #For 4x4 resolution\n",
    "        self.initial_rgb = WSConv2d(img_channels, in_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.rgb_layers.append(self.initial_rgb)\n",
    "        \n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size=2, stride=2)  # down sampling using avg pool\n",
    "\n",
    "        # this is the block for 4x4 input size\n",
    "        self.final_block = nn.Sequential(\n",
    "            # +1 to in_channels because we concatenate from MiniBatch std\n",
    "            WSConv2d(in_channels + 1, in_channels, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            WSConv2d(in_channels, in_channels, kernel_size=4, padding=0, stride=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            WSConv2d(in_channels, 1, kernel_size=1, padding=0, stride=1),  # this pretty much is a linear layer\n",
    "        )\n",
    "    def fade_in(self, alpha, downscaled, out):\n",
    "        \"\"\"Used to fade in downscaled using avg pooling and output from CNN\"\"\"\n",
    "        # alpha should be scalar within [0, 1], and upscale.shape == generated.shape\n",
    "        return alpha * out + (1 - alpha) * downscaled\n",
    "\n",
    "    def minibatch_std(self, x):\n",
    "        batch_statistics = (torch.std(x, dim=0).mean().repeat(x.shape[0], 1, x.shape[2], x.shape[3]))\n",
    "        # we take the std for each example (across all channels, and pixels) then we repeat it\n",
    "        # for a single channel and concatenate it with the image. In this way the discriminator\n",
    "        # will get information about the variation in the batch/image\n",
    "        return torch.cat([x, batch_statistics], dim=1)    \n",
    "     \n",
    "    def forward(self, x, alpha, steps):\n",
    "        # where we should start in the list of prog_blocks, maybe a bit confusing but\n",
    "        # the last is for the 4x4. So example let's say steps=1, then we should start\n",
    "        # at the second to last because input_size will be 8x8. If steps==0 we just\n",
    "        # use the final block\n",
    "        cur_step = len(self.prog_blocks) - steps\n",
    "\n",
    "        # convert from rgb as initial step, this will depend on\n",
    "        # the image size (each will have it's on rgb layer)\n",
    "        out = self.leaky(self.rgb_layers[cur_step](x))\n",
    "\n",
    "        if steps == 0:  # i.e, image is 4x4\n",
    "            out = self.minibatch_std(out)\n",
    "            return self.final_block(out).view(out.shape[0], -1)\n",
    "\n",
    "        # because prog_blocks might change the channels, for down scale we use rgb_layer\n",
    "        # from previous/smaller size which in our case correlates to +1 in the indexing\n",
    "        downscaled = self.leaky(self.rgb_layers[cur_step + 1](self.avg_pool(x)))\n",
    "        out = self.avg_pool(self.prog_blocks[cur_step](out))\n",
    "\n",
    "        # the fade_in is done first between the downscaled and the input\n",
    "        # this is opposite from the generator\n",
    "        out = self.fade_in(alpha, downscaled, out)\n",
    "\n",
    "        for step in range(cur_step + 1, len(self.prog_blocks)):\n",
    "            out = self.prog_blocks[step](out)\n",
    "            out = self.avg_pool(out)\n",
    "\n",
    "        out = self.minibatch_std(out)\n",
    "        return self.final_block(out).view(out.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77617f2e",
   "metadata": {
    "id": "77617f2e"
   },
   "source": [
    "if __name__ == \"__main__\":\n",
    "    Z_DIM = 512\n",
    "    IN_CHANNELS = 512\n",
    "    gen = Generator(Z_DIM, IN_CHANNELS, img_channels=3)\n",
    "    critic = Discriminator(IN_CHANNELS, img_channels=3)\n",
    "\n",
    "    for img_size in [4, 8, 16, 32, 64, 128, 256, 512, 1024]:\n",
    "        num_steps = int(log2(img_size / 4))\n",
    "        x = torch.randn((1, Z_DIM, 1, 1))\n",
    "        z = gen(x, 0.5, steps=num_steps)\n",
    "        assert z.shape == (1, 3, img_size, img_size)\n",
    "        out = critic(z, alpha=0.5, steps=num_steps)\n",
    "        assert out.shape == (1, 1)\n",
    "        print(f\"Success! At img size: {img_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81d0b1a",
   "metadata": {
    "id": "b81d0b1a"
   },
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == ConvTranspose2d:\n",
    "        nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    elif type(m) == BatchNorm2d:\n",
    "        nn.init.normal_(m.weight, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b3c16f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2698,
     "status": "ok",
     "timestamp": 1680844841248,
     "user": {
      "displayName": "Kaspars Pakulis",
      "userId": "15620035111695870681"
     },
     "user_tz": -180
    },
    "id": "9b3c16f9",
    "outputId": "7741aeb5-9214-4b6d-ae1d-8f209365b65b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint\n",
      "=> Loading checkpoint\n"
     ]
    }
   ],
   "source": [
    "# creating gen and disc\n",
    "netG = Generator(Z_DIM, IN_CHANNELS, img_channels=CHANNELS_IMG).to(device)\n",
    "netD = Discriminator(IN_CHANNELS, img_channels=CHANNELS_IMG).to(device)\n",
    "\n",
    "# initialize optimizers and scalers for FP16 training\n",
    "opt_D = optim.Adam(netD.parameters(), lr = LEARNING_RATE, betas= (0.0, 0.99))\n",
    "opt_G = optim.Adam(netG.parameters(), lr = LEARNING_RATE, betas= (0.0, 0.99))\n",
    "\n",
    "scaler_D = torch.cuda.amp.GradScaler()\n",
    "scaler_G = torch.cuda.amp.GradScaler()\n",
    "# Setting up the loss function - BCELoss (to check how far the predicted value is from real value)\n",
    "\n",
    "if LOAD_MODEL:\n",
    "        load_checkpoint(CHECKPOINT_G, netG, opt_G, LEARNING_RATE,)\n",
    "        load_checkpoint(CHECKPOINT_D, netD, opt_D, LEARNING_RATE,)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "675a03d7",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1680844842718,
     "user": {
      "displayName": "Kaspars Pakulis",
      "userId": "15620035111695870681"
     },
     "user_tz": -180
    },
    "id": "675a03d7"
   },
   "outputs": [],
   "source": [
    "def train_fn(netD, netG, loader, dataset, step, alpha, opt_D, opt_G, tensorboard_step, scaler_G, scaler_D):\n",
    "    d_loss_lst = ['D']\n",
    "    g_loss_lst = ['G']\n",
    "    loop = tqdm(loader, leave=True)\n",
    "    for batch_idx, (real, _) in enumerate(loop):\n",
    "        \n",
    "        real = real.to(device)\n",
    "        cur_batch_size = real.shape[0]\n",
    "\n",
    "        # Train Critic: max E[critic(real)] - E[critic(fake)] <-> min -E[critic(real)] + E[critic(fake)]\n",
    "        # which is equivalent to minimizing the negative of the expression\n",
    "        noise = torch.randn(cur_batch_size, Z_DIM, 1, 1).to(device)\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            fake = netG(noise, alpha, step)\n",
    "            netD_real = netD(real, alpha, step)\n",
    "            netD_fake = netD(fake.detach(), alpha, step)\n",
    "            gp = gradient_penalty(netD, real, fake, alpha, step, device=device)\n",
    "            loss_D = (-(torch.mean(netD_real) - torch.mean(netD_fake)) + LAMBDA_GP * gp + (0.001 * torch.mean(netD_real ** 2)))\n",
    "\n",
    "        opt_D.zero_grad()\n",
    "        scaler_D.scale(loss_D).backward()\n",
    "        scaler_D.step(opt_D)\n",
    "        scaler_D.update()\n",
    "        d_loss_lst.append(loss_D.item())\n",
    "\n",
    "        # Train Generator: max E[critic(gen_fake)] <-> min -E[critic(gen_fake)]\n",
    "        with torch.cuda.amp.autocast():\n",
    "            gen_fake = netD(fake, alpha, step)\n",
    "            loss_G = -torch.mean(gen_fake)\n",
    "\n",
    "        opt_G.zero_grad()\n",
    "        scaler_G.scale(loss_G).backward()\n",
    "        scaler_G.step(opt_G)\n",
    "        scaler_G.update()\n",
    "        g_loss_lst.append(loss_G.item())\n",
    "\n",
    "        # Update alpha and ensure less than 1\n",
    "        alpha += cur_batch_size / ((PROGRESSIVE_EPOCHS[step] * 0.5) * len(dataset))\n",
    "        alpha = min(alpha, 1)\n",
    "\n",
    "        if batch_idx % 500 == 0:\n",
    "            with torch.no_grad():\n",
    "                fixed_fakes = netG(FIXED_NOISE, alpha, step) * 0.5 + 0.5\n",
    "            tensorboard_step += 1\n",
    "        \n",
    "        loop.set_postfix(\n",
    "            gp=gp.item(),\n",
    "            loss_D=loss_D.item(),\n",
    "        )\n",
    "        \n",
    "    with open('lossM.csv', 'a') as f:\n",
    "        write = csv.writer(f)  \n",
    "        write.writerow(d_loss_lst)\n",
    "        write.writerow(g_loss_lst)\n",
    "        f.close()\n",
    "    return tensorboard_step, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "349c4c9f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 903
    },
    "executionInfo": {
     "elapsed": 10787560,
     "status": "error",
     "timestamp": 1680868859020,
     "user": {
      "displayName": "Kaspars Pakulis",
      "userId": "15620035111695870681"
     },
     "user_tz": -180
    },
    "id": "349c4c9f",
    "outputId": "618c92c3-17b9-4cbd-ae1e-09131b36a959",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image size: 256\n",
      "Epoch [1/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:40<00:00,  2.43it/s, gp=0.00377, loss_D=-34]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [2/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:34<00:00,  2.49it/s, gp=0.0505, loss_D=-4.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [3/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.0792, loss_D=-17.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [4/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.096, loss_D=-14.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [5/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.0231, loss_D=12.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [6/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.0662, loss_D=-6.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [7/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.104, loss_D=-.607]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [8/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.0778, loss_D=7.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [9/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.122, loss_D=-3.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [10/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.0451, loss_D=-6.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [11/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.11, loss_D=-17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [12/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.102, loss_D=-14.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [13/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.0217, loss_D=-.974]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [14/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.064, loss_D=2.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [15/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.0458, loss_D=3.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [16/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.00336, loss_D=-.618]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [17/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.0925, loss_D=11.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [18/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.0521, loss_D=-17.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [19/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.159, loss_D=-25.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [20/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.0388, loss_D=-5.67]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [21/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.0134, loss_D=1.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [22/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.0144, loss_D=-1.66]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [23/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.0324, loss_D=6.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [24/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.0413, loss_D=11.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [25/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.0107, loss_D=0.153]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [26/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.0145, loss_D=-11.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [27/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.164, loss_D=-13.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [28/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.0602, loss_D=-3.64]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [29/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.0319, loss_D=-6.18]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [30/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.108, loss_D=8.71]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [31/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.0105, loss_D=1.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [32/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.0347, loss_D=-1.69]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [33/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.104, loss_D=4.17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [34/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.0224, loss_D=14.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [35/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.0841, loss_D=-2.59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [36/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.0214, loss_D=2.26]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [37/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.0375, loss_D=1.38]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [38/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.0784, loss_D=-.492]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [39/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.0157, loss_D=-6.29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [40/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.0092, loss_D=-.138]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [41/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.0478, loss_D=-16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [42/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.111, loss_D=-11.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [43/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.129, loss_D=10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [44/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.0259, loss_D=4.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [45/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.122, loss_D=-23.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [46/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.114, loss_D=-12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [47/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.0479, loss_D=1.26]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [48/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.0601, loss_D=4.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [49/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.095, loss_D=-10.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [50/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.121, loss_D=-26.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [51/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.151, loss_D=-9.92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [52/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.0821, loss_D=-11.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [53/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.0339, loss_D=-24.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [54/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.0694, loss_D=-13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [55/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.0765, loss_D=-11.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [56/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.0264, loss_D=-14.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [57/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.091, loss_D=-15.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [58/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.0202, loss_D=-9.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [59/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:38<00:00,  2.45it/s, gp=0.0343, loss_D=-10.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [60/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:33<00:00,  2.50it/s, gp=0.0115, loss_D=-5.92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [61/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.0611, loss_D=-9.59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [62/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.0323, loss_D=-1.39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [63/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.0554, loss_D=-3.05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [64/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.016, loss_D=4.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [65/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.0991, loss_D=4.32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [66/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.0455, loss_D=4.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [67/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.0185, loss_D=0.611]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [68/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.0816, loss_D=-1.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [69/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.0647, loss_D=-18.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [70/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.0576, loss_D=-12.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [71/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.164, loss_D=1.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [72/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.176, loss_D=-.807]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [73/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.0438, loss_D=5.24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [74/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.0258, loss_D=2.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [75/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:35<00:00,  2.49it/s, gp=0.0388, loss_D=1.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [76/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:34<00:00,  2.49it/s, gp=0.0679, loss_D=8.28]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [77/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.0731, loss_D=-.0798]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [78/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.0284, loss_D=6.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [79/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.0577, loss_D=-13.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [80/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.0854, loss_D=-6.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [81/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:35<00:00,  2.48it/s, gp=0.333, loss_D=-3.46]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [82/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:37<00:00,  2.46it/s, gp=0.0655, loss_D=7.18]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [83/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 535/535 [03:37<00:00,  2.45it/s, gp=0.000785, loss_D=-10.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [84/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 535/535 [03:34<00:00,  2.50it/s, gp=0.00661, loss_D=-6.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [85/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.0307, loss_D=-7.72]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [86/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.129, loss_D=3.93]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [87/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.0221, loss_D=18.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [88/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.221, loss_D=3.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [89/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.132, loss_D=-5.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [90/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.51it/s, gp=0.0488, loss_D=-3.71]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [91/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.0289, loss_D=-14.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [92/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.114, loss_D=-2.24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [93/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:32<00:00,  2.52it/s, gp=0.0363, loss_D=-14.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [94/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:37<00:00,  2.46it/s, gp=0.0835, loss_D=-17.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [95/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:37<00:00,  2.46it/s, gp=0.0181, loss_D=-4.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [96/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:37<00:00,  2.46it/s, gp=0.0548, loss_D=-5.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [97/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:37<00:00,  2.45it/s, gp=0.0127, loss_D=-5.34]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [98/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:37<00:00,  2.46it/s, gp=0.0377, loss_D=-11.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [99/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:38<00:00,  2.44it/s, gp=0.0717, loss_D=-12.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch [100/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 535/535 [03:37<00:00,  2.46it/s, gp=0.0543, loss_D=-17.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "Current image size: 512\n",
      "Epoch [1/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                      | 12/1069 [00:11<16:29,  1.07it/s, gp=0.0849, loss_D=-3.83]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m     tensorboard_step, alpha \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnetG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_D\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_G\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensorboard_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mscaler_G\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler_D\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SAVE_MODEL:\n\u001b[0;32m     15\u001b[0m         save_checkpoint(netG, opt_G, filename\u001b[38;5;241m=\u001b[39mCHECKPOINT_G)\n",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m, in \u001b[0;36mtrain_fn\u001b[1;34m(netD, netG, loader, dataset, step, alpha, opt_D, opt_G, tensorboard_step, scaler_G, scaler_D)\u001b[0m\n\u001b[0;32m      4\u001b[0m loop \u001b[38;5;241m=\u001b[39m tqdm(loader, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (real, _) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loop):\n\u001b[1;32m----> 7\u001b[0m     real \u001b[38;5;241m=\u001b[39m \u001b[43mreal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     cur_batch_size \u001b[38;5;241m=\u001b[39m real\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Train Critic: max E[critic(real)] - E[critic(fake)] <-> min -E[critic(real)] + E[critic(fake)]\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# which is equivalent to minimizing the negative of the expression\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "netG.train()\n",
    "netD.train()\n",
    "tensorboard_step = 0\n",
    "# start at step that corresponds to img size that we set in config\n",
    "step = int(log2(START_TRAIN_AT_IMG_SIZE / 4))\n",
    "for num_epochs in PROGRESSIVE_EPOCHS[step:]:\n",
    "    alpha = 1e-5  # start with very low alpha\n",
    "    loader, dataset = get_loader(4 * 2 ** step)  # 4->0, 8->1, 16->2, 32->3, 64 -> 4\n",
    "    print(f\"Current image size: {4 * 2 ** step}\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "        tensorboard_step, alpha = train_fn(netD, netG, loader, dataset, step, alpha, opt_D, opt_G, tensorboard_step,  scaler_G, scaler_D)\n",
    "        if SAVE_MODEL:\n",
    "            save_checkpoint(netG, opt_G, filename=CHECKPOINT_G)\n",
    "            save_checkpoint(netD, opt_D, filename=CHECKPOINT_D)\n",
    "\n",
    "    step += 1  # progress to the next img size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827af2ed",
   "metadata": {
    "id": "827af2ed"
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(d_loss, g_loss):\n",
    "  fig = plt.figure()\n",
    "  plt.plot(d_loss, color='skyblue')\n",
    "  plt.plot(g_loss, color='gold')\n",
    "  plt.title('Model Learning Curve')\n",
    "  plt.xlabel('Epochs'); plt.ylabel('Loss')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c09756",
   "metadata": {
    "id": "40c09756"
   },
   "source": [
    "torch.save(netG.state_dict(), r'C:\\Users\\Unreal User\\Kaspars\\netG.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b83081c",
   "metadata": {
    "id": "9b83081c"
   },
   "source": [
    "noise = torch.randn(32, 100, 1, 1, device = device)\n",
    "generated_samples = netG(noise)\n",
    "img_plot = np.transpose(generated_samples.detach().cpu(), (0,2,3,1)) # .detach().cpu() is imp for copying fake_img tensor to host memory first\n",
    "plot_images(img_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ed11f9",
   "metadata": {
    "id": "c9ed11f9"
   },
   "source": [
    "model = Generator().to(device)\n",
    "model.load_state_dict(torch.load(r'C:\\Users\\Unreal User\\Kaspars\\netG.pth'))\n",
    "model.eval()\n",
    "size = 32\n",
    "noise = torch.randn(size, 100, 1, 1, device = device)\n",
    "generated_samples = model(noise)\n",
    "img_plot = np.transpose(generated_samples.detach().cpu(), (0,2,3,1)) # .detach().cpu() is imp for copying fake_img tensor to host memory first\n",
    "plot_images(img_plot)\n",
    "save_images_func(generated_samples, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc07c02e",
   "metadata": {
    "executionInfo": {
     "elapsed": 259,
     "status": "ok",
     "timestamp": 1680844849034,
     "user": {
      "displayName": "Kaspars Pakulis",
      "userId": "15620035111695870681"
     },
     "user_tz": -180
    },
    "id": "cc07c02e"
   },
   "outputs": [],
   "source": [
    "def generate_examples(gen, steps, truncation=0.7, n=100):\n",
    "    \"\"\"\n",
    "    Tried using truncation trick here but not sure it actually helped anything, you can\n",
    "    remove it if you like and just sample from torch.randn\n",
    "    \"\"\"\n",
    "    gen.eval()\n",
    "    alpha = 1.0\n",
    "    for i in range(n):\n",
    "        with torch.no_grad():\n",
    "            noise = torch.tensor(truncnorm.rvs(-truncation, truncation, size=(1, Z_DIM, 1, 1)), device=device, dtype=torch.float32)\n",
    "            img = gen(noise, alpha, steps)\n",
    "            save_image(img*0.5+0.5, f\"img_{i}.png\")\n",
    "    gen.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7122be3",
   "metadata": {},
   "source": [
    "Ká redzams, sákotnéjá mapé neeksistéja neviena bilde.\n",
    "\n",
    "Programma strádá bez klúdám, tas kas ir redzams augsták ir trené'sanas bloks, kuru nácá spielietot KeyboardInterrupt.\n",
    "\n",
    "Tagad tiks generéti 10 512x512 attéli ar melanomám\n",
    "\n",
    "Atteli nav perfekti , jo tíklam nepieciesami papildus trenins, taçu tie ie pietiekami skaidri\n",
    "\n",
    "Péc tam es parádísu sakotnéjos attelus lai varétu salídzinát. Sakotnéjie attéli ir 1024x1024, Tikls spéj 'generét 1024x1024 bet pagaidam nav uz to trenéts, jo yas aiz'nem 'loti daudz laika."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b617c658",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(d_loss_lst, g_loss_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "IsjtgSsUnTNY",
   "metadata": {
    "executionInfo": {
     "elapsed": 3090,
     "status": "ok",
     "timestamp": 1680868875806,
     "user": {
      "displayName": "Kaspars Pakulis",
      "userId": "15620035111695870681"
     },
     "user_tz": -180
    },
    "id": "IsjtgSsUnTNY"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 7 is out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgenerate_examples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetG\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 11\u001b[0m, in \u001b[0;36mgenerate_examples\u001b[1;34m(gen, steps, truncation, n)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     10\u001b[0m         noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(truncnorm\u001b[38;5;241m.\u001b[39mrvs(\u001b[38;5;241m-\u001b[39mtruncation, truncation, size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, Z_DIM, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)), device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m---> 11\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m         save_image(img\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m gen\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[7], line 36\u001b[0m, in \u001b[0;36mGenerator.forward\u001b[1;34m(self, x, alpha, steps)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(steps):\n\u001b[0;32m     35\u001b[0m     upscaled \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(out, scale_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 36\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprog_blocks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m]\u001b[49m(upscaled)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# The number of channels in upscale will stay the same, while\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# out which has moved through prog_blocks might change. To ensure\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# we can convert both to rgb we use different rgb_layers\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# (steps-1) and steps for upscaled, out respectively\u001b[39;00m\n\u001b[0;32m     42\u001b[0m final_upscaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrgb_layers[steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m](upscaled)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:295\u001b[0m, in \u001b[0;36mModuleList.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mvalues())[idx])\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules[\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_abs_string_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:285\u001b[0m, in \u001b[0;36mModuleList._get_abs_string_index\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    283\u001b[0m idx \u001b[38;5;241m=\u001b[39m operator\u001b[38;5;241m.\u001b[39mindex(idx)\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)):\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is out of range\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(idx))\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    287\u001b[0m     idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 7 is out of range"
     ]
    }
   ],
   "source": [
    "generate_examples(netG,7, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4e97d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bec463",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
